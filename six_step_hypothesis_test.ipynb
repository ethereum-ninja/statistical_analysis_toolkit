{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bokeh'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0d801136b159>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbokeh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayouts\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgridplot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbokeh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplotting\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bokeh'"
     ]
    }
   ],
   "source": [
    "import statistical_analysis_toolkit as stat_tools\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "#n = stat_tools.critical_norm(.01)\n",
    "df = 8\n",
    "a = 0.05\n",
    "t = stat_tools.critical_t(a, df) #two sided\n",
    "t1 = stats.t.ppf(a, df) #one sided, lower\n",
    "[t, t1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "education_data = pd.read_csv('/Users/skennedy/Documents/SMU/Stats/Homework/HW5/ex0525.csv')[['Educ', 'Income2005']]\n",
    "#education_data['LogIncome2005'] = np.log(education_data.Income2005)\n",
    "education_data.Educ.replace('<12', '12', inplace=True)\n",
    "education_data.Educ.replace('>16', '16', inplace=True)\n",
    "education_data.to_csv('education_data.csv')\n",
    "anova(education_data, 'Educ', 'Income2005')\n",
    "\n",
    "#{   for education_level, data in education_data.groupby(['Educ'])}\n",
    "    \n",
    "#prep data for an anova test (one data frame with multiple columns as samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def anova(data, partition_column, observable_column):\n",
    "    #test assumptions of anova graphically and numerically\n",
    "    \n",
    "    '''1) Normality: Similar to t-tools hypothesis testing, ANOVA is robust to this assumption.  \n",
    "        Extremely long-tailed distributions (outliers) or skewed distributions, \n",
    "        coupled with different sample sizes (especially when the sample sizes are small) \n",
    "        present the only serious distributional problems.'''\n",
    "    \n",
    "    '''2) Equal Standard Deviations: This assumption is crucial, paramount, and VERY important.''' \n",
    "    \n",
    "    '''3) The assumptions of independence within and across groups are critical.  \n",
    "            If lacking, different analysis should be attempted.'''\n",
    "    make_histogram_plots(data, partition_column=partition_column, observable_column=observable_column)\n",
    "    #Create logical groupings\n",
    "    #groups = data.groupby([partition_column])\n",
    "    #hist_fig, hist_ax = plt.subplots(len(groups), 1, sharex=True)\n",
    "    #hist_fig.suptitle('Histograms Raw Data')\n",
    "    #hist_fig_log, hist_ax_log = plt.subplots(len(groups), 1, sharex=True)\n",
    "    #hist_fig_log.suptitle('Histograms Log Data')\n",
    "    #i = 0\n",
    "    #group_stats = []\n",
    "    #for group_key, group in groups:\n",
    "    #    clean_data  = group[observable_column].dropna()\n",
    "    #    group_std = clean_data.std()\n",
    "    #    group_mean = clean_data.mean()\n",
    "        \n",
    "        #plot histograms\n",
    "    #    hist_ax[i].hist(clean_data)\n",
    "    #    hist_ax[i].set_title(group_key)\n",
    "    #    log_data = np.log(clean_data[clean_data != 0])\n",
    "    #    hist_ax_log[i].hist(log_data)\n",
    "     \n",
    "        \n",
    "     #   i = i + 1\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def make_histogram_plots(data, partition_column, observable_column):\n",
    "    groups = data.groupby([partition_column])\n",
    "    #plots \n",
    "    histograms = []\n",
    "    for group_key, group in groups:\n",
    "        #x, pdf, cdf, \n",
    "        clean_data  = group[observable_column].dropna()\n",
    "        group_std = clean_data.std()\n",
    "        group_mean = clean_data.mean()\n",
    "        pdf = stats.norm.pdf(clean_data)\n",
    "        cdf = stats.norm.cdf(clean_data)\n",
    "        hist, edges = np.histogram(clean_data, density=True, bins='auto')\n",
    "        p = figure(title=f'Group {group_key} Mean {round(group_mean, 2)} Std {round(group_std,2)}', tools='', background_fill_color=\"#fafafa\")\n",
    "        p.quad(top=hist, bottom=0, left=edges[:-1], right=edges[1:],\n",
    "               fill_color=\"navy\", line_color=\"white\", alpha=0.5)\n",
    "        p.line(clean_data, pdf, line_color=\"#ff8888\", line_width=4, alpha=0.7, legend=\"PDF\")\n",
    "        p.line(clean_data, cdf, line_color=\"orange\", line_width=2, alpha=0.7, legend=\"CDF\")\n",
    "        p.y_range.start = 0\n",
    "        p.legend.location = \"center_right\"\n",
    "        p.legend.background_fill_color = \"#fefefe\"\n",
    "        p.xaxis.axis_label = 'x'\n",
    "        p.yaxis.axis_label = 'Pr(x)'\n",
    "        p.grid.grid_line_color=\"white\"\n",
    "        histograms.append(p)\n",
    "    \n",
    "    show(gridplot(histograms, ncols=1, plot_width=400, plot_height=400, toolbar_location=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method cdf in module scipy.stats._distn_infrastructure:\n",
      "\n",
      "cdf(x, *args, **kwds) method of scipy.stats._continuous_distns.norm_gen instance\n",
      "    Cumulative distribution function of the given RV.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    x : array_like\n",
      "        quantiles\n",
      "    arg1, arg2, arg3,... : array_like\n",
      "        The shape parameter(s) for the distribution (see docstring of the\n",
      "        instance object for more information)\n",
      "    loc : array_like, optional\n",
      "        location parameter (default=0)\n",
      "    scale : array_like, optional\n",
      "        scale parameter (default=1)\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    cdf : ndarray\n",
      "        Cumulative distribution function evaluated at `x`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(stats.norm.cdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bokeh' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-17f293ac17cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhelp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbokeh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'bokeh' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
